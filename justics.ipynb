{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Creating new text file\n",
      "1\n",
      "Creating new text file\n",
      "1.txt\n",
      "data/justice/raw/1.txt\n",
      "<_io.TextIOWrapper name='data/justice/raw/1.txt' mode='w' encoding='UTF-8'>\n",
      "2\n",
      "Creating new text file\n",
      "2.txt\n",
      "data/justice/raw/2.txt\n",
      "<_io.TextIOWrapper name='data/justice/raw/2.txt' mode='w' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "import io\n",
    "import numpy as np \n",
    "import sklearn.feature_extraction.text as text\n",
    "from sklearn import decomposition\n",
    "\n",
    "\n",
    "PDF_PATH = os.path.join('data', 'justice','pdfs')\n",
    "PDF_NAMES = os.listdir(PDF_PATH)\n",
    "CORPUS_PATH = os.path.join('data','justice','txt')\n",
    "\n",
    "# CORPUS_PATH = os.path.join('data', 'austen-brontÃ«-split')\n",
    "# print(PDF_PATH)\n",
    "# print(PDF_NAMES)\n",
    "# print(CORPUS_PATH)\n",
    "\n",
    "#make a list of pdf files names\n",
    "#go through each of them and write them to the same directory as a text file \n",
    "\n",
    "pdffilenames = sorted([os.path.join(PDF_PATH, fn) for fn in os.listdir(PDF_PATH)])\n",
    "# print(pdffilenames)\n",
    "\n",
    "\n",
    "def pdfparser(data):\n",
    "\n",
    "    fp = open(data, 'rb')\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    # Create a PDF interpreter object.\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    # Process each page contained in the document.\n",
    "\n",
    "    for page in PDFPage.get_pages(fp):\n",
    "        interpreter.process_page(page)\n",
    "        data =  retstr.getvalue()\n",
    "\n",
    "#     print(data)\n",
    "    return data\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "# pdfparser(CORPUS_PATH)  \n",
    "\n",
    "\n",
    "def pdfConverter(arrayOfFullFileNames, arrayOfPDFNames, destPath):\n",
    "    for i in range(len(arrayOfFullFileNames)):\n",
    "        print(i)\n",
    "        print('Creating new text file') \n",
    "        if not str(arrayOfPDFNames[i]).startswith('.'):\n",
    "            name = str(i) + '.txt'\n",
    "            print(name)\n",
    "            try:\n",
    "                content = pdfparser(arrayOfFullFileNames[i])\n",
    "                contenttwo = str(content)\n",
    "                finalFile = os.path.join('data','justice','raw', name)\n",
    "                print(finalFile)\n",
    "                file = open(finalFile,'w')\n",
    "                print(file)\n",
    "                file.write(str(contenttwo))\n",
    "                file.close()\n",
    "            except:\n",
    "                print('Something went wrong! Can\\'t tell what?')\n",
    "                sys.exit(0) # quit Python\n",
    "        \n",
    "        \n",
    "pdfConverter(pdffilenames,PDF_NAMES,CORPUS_PATH) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "data/justice/txt/.DS_Store\n",
      "1\n",
      "data/justice/txt/1.txt\n",
      "2\n",
      "data/justice/txt/2.txt\n"
     ]
    }
   ],
   "source": [
    "#now delete dot files from that directory for cleanup\n",
    "# arrayOfFiles = \n",
    "# textFiles = sorted([os.path.join(CORPUS_PATH, fn) for fn in os.listdir(CORPUS_PATH)])\n",
    "\n",
    "# for i in range(len(textFiles)):\n",
    "#     print(textFiles)\n",
    "#     print(i)\n",
    "#     print(textFiles[i])\n",
    "#     if not str(textFiles[i]).startswith('.'):\n",
    "#         print(i)\n",
    "#         print(textFiles[i])\n",
    "    #   filenames = sorted([os.path.join(CORPUS_PATH, fn) for fn in os.listdir(CORPUS_PATH)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = sorted([os.path.join(CORPUS_PATH, fn) for fn in os.listdir(CORPUS_PATH)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = text.CountVectorizer(input='filename', stop_words='english', min_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/justice/txt/1.txt', 'data/justice/txt/2.txt']\n",
      "[[1 0 2 ..., 1 0 1]\n",
      " [1 1 0 ..., 0 1 2]]\n",
      "['00' '000' '0025' '0030' '10' '11' '110' '111' '12' '13' '1300' '1373815'\n",
      " '14' '15' '16' '16458' '165' '17' '17th' '18' '180' '20' '2008' '2015'\n",
      " '2017' '2018' '237' '24' '30' '3_' '92649' '92651' '95814' '_establish'\n",
      " 'ability' 'able' 'absence' 'absolute' 'abstinence' 'academic' 'accept'\n",
      " 'acceptable' 'accepted' 'access' 'accessible' 'accordance' 'according'\n",
      " 'accounting' 'accredited' 'act' 'action' 'actively' 'activity' 'acts'\n",
      " 'actual' 'added' 'addition' 'administer' 'admission' 'adoption' 'adults'\n",
      " 'advance' 'age' 'agencies' 'agreements' 'aids' 'alternative' 'amendment'\n",
      " 'amendments' 'americans' 'amortize' 'amortized' 'appeal' 'appear'\n",
      " 'applicable' 'apply' 'appoint' 'appointed' 'appointing' 'appropriate'\n",
      " 'appropriated' 'approval' 'approved' 'arndt' 'article' 'ashley'\n",
      " 'astounding' 'attend' 'attendance' 'attending' 'attention' 'attorney'\n",
      " 'audit' 'august' 'authority' 'authorize' 'authorized' 'ballot' 'base'\n",
      " 'based' 'basis' 'beach' 'behaviors' 'beliefs' 'better' 'billboards'\n",
      " 'billion' 'bisexual' 'boldface' 'bolsa' 'bonds' 'book' 'books' 'bookstore'\n",
      " 'bounds' 'boyd' 'budget' 'buy' 'buyers' 'ca' 'california' 'care' 'cases'\n",
      " 'causing' 'ccc' 'cdc' 'certifications' 'chairman' 'challenging' 'changes'\n",
      " 'charge' 'charged' 'check' 'chica' 'chief' 'child' 'children' 'christian'\n",
      " 'circulating' 'cited' 'citizen' 'classes' 'code' 'coercion' 'colleges'\n",
      " 'com' 'command' 'committee' 'community' 'complete' 'completing'\n",
      " 'comprised' 'conservative' 'consisting' 'consists' 'constitution'\n",
      " 'constitutional' 'constitutionality' 'contract' 'contrary' 'control'\n",
      " 'controlling' 'coordinator' 'correspondence' 'corrupted' 'cost' 'costs'\n",
      " 'county' 'course' 'courses' 'court' 'cover' 'create' 'creating' 'creation'\n",
      " 'creator' 'creators' 'credit' 'csu' 'curriculum' 'data' 'day' 'days'\n",
      " 'dear' 'decades' 'declarations' 'declare' 'defend' 'defending'\n",
      " 'degeneracy' 'degree' 'degrees' 'deliver' 'demand' 'depart' 'designed'\n",
      " 'devise' 'dictate' 'digital' 'direct' 'directly' 'discourse'\n",
      " 'discretionary' 'disease' 'disruptive' 'division' 'divisions' 'drives'\n",
      " 'duplicates' 'duration' 'earlier' 'earn' 'education' 'educational'\n",
      " 'election' 'elections' 'emailed' 'employee' 'enclosed' 'enclosure'\n",
      " 'enclosures' 'encourage' 'end' 'endowed' 'endowment' 'enroll' 'enrollment'\n",
      " 'ensure' 'entirety' 'entities' 'entity' 'environment' 'eradicate' 'erect'\n",
      " 'especially' 'essence' 'establish' 'established' 'establishing'\n",
      " 'estimated' 'estimates' 'event' 'ex' 'exceed' 'exclude' 'excluding'\n",
      " 'expected' 'expenses' 'exploits' 'express' 'facilitate' 'fact' 'faculty'\n",
      " 'fail' 'fair' 'fee' 'fees' 'financing' 'finding' 'findings' 'finish'\n",
      " 'fixed' 'floor' 'following' 'follows' 'food' 'fornication' 'forth'\n",
      " 'foundation' 'free' 'fully' 'fund' 'funding' 'funds' 'fungible' 'gallery'\n",
      " 'gatekeeping' 'gay' 'general' 'given' 'good' 'government' 'governmental'\n",
      " 'governor' 'governors' 'guardian' 'guardians' 'gun' 'half' 'harvey'\n",
      " 'health' 'healthcare' 'healthy' 'held' 'high' 'highest' 'home'\n",
      " 'homoerotic' 'homosexual' 'homosexuality' 'honorable' 'honoring' 'housing'\n",
      " 'humanism' 'huntington' 'i4' 'id' 'identified' 'identifier' 'idolizing'\n",
      " 'ifthe' 'ii' 'immoral' 'immorally' 'impacted' 'impacting' 'implement'\n",
      " 'impossible' 'include' 'including' 'increasingly' 'indoctrinated'\n",
      " 'infections' 'initial' 'initiative' 'initiatne' 'inquiries' 'instructions'\n",
      " 'intended' 'intent' 'interference' 'intervene' 'inviolable' 'ism' 'issue'\n",
      " 'item' 'ix' 'jnitiative' 'joaquin' 'johansson' 'judeo' 'known' 'lab'\n",
      " 'laboratory' 'labs' 'laguna' 'language' 'large' 'law' 'lead' 'lee'\n",
      " 'leftist' 'legal' 'legitimate' 'letter' 'level' 'libraries' 'lies' 'life'\n",
      " 'limited' 'limiting' 'line' 'listed' 'lives' 'living' 'lo' 'local' 'long'\n",
      " 'low' 'lower' 'lu' 'majority' 'make' 'makes' 'man' 'market' 'marriage'\n",
      " 'materials' 'matter' 'maximize' 'meanings' 'means' 'measure' 'meet'\n",
      " 'meets' 'member' 'men' 'merit' 'methods' 'milk' 'million' 'minimize'\n",
      " 'moral' 'morally' 'morals' 'ms' 'necessary' 'need' 'negotiate' 'new'\n",
      " 'nline' 'nonprofit' 'notivithstanding' 'notwithstanding' 'number'\n",
      " 'numeric' 'o2' 'occur' 'oct' 'october' 'of2018' 'office' 'officials'\n",
      " 'officio' 'offline' 'oflaw' 'ofthe' 'oftheir' 'ofthis' 'okay' 'old'\n",
      " 'olson' 'online' 'open' 'options' 'orange' 'org' 'outside' 'owned' 'pace'\n",
      " 'page' 'pantries' 'papers' 'paragraph' 'parent' 'parental' 'parents'\n",
      " 'pass' 'path' 'pay' 'payer' 'pcu' 'people' 'petition' 'physical'\n",
      " 'physically' 'plan' 'plea' 'pleasure' 'point' 'points' 'political'\n",
      " 'portion' 'possibly' 'postsecondary' 'power' 'powers' 'praised' 'prepare'\n",
      " 'prepared' 'present' 'president' 'press' 'price' 'prices' 'primarily'\n",
      " 'principles' 'printed' 'prior' 'private' 'process' 'proctored'\n",
      " 'proctoring' 'professor' 'professors' 'program' 'programs' 'projected'\n",
      " 'projections' 'promote' 'promotion' 'promptly' 'propaganda' 'proponent'\n",
      " 'propose' 'proposed' 'prorated' 'provided' 'provision' 'public'\n",
      " 'publically' 'publicly' 'purpose' 'purposes' 'pursuant' 'quadrupling'\n",
      " 'qualified' 'quality' 'question' 'r7' 'raising' 'rates' 'read' 'ready'\n",
      " 'realestate' 'reason' 'reasons' 'received' 'reciprocal' 'redline'\n",
      " 'reflect' 'reflecting' 'regarding' 'regards' 'regents' 'registered'\n",
      " 'reject' 'rejection' 'relating' 'repay' 'request' 'requests' 'require'\n",
      " 'required' 'requires' 'residents' 'resources' 'respective' 'respectively'\n",
      " 'responsibility' 'resulted' 'revealed' 'revenues' 'review' 'revised'\n",
      " 'revision' 'right' 'rights' 'rigorous' 'roberts' 'roman' 'roughly'\n",
      " 'sacramento' 'said' 'san' 'sanctioned' 'satisfied' 'schedule'\n",
      " 'scholarship' 'scholarships' 'school' 'schools' 'science' 'search'\n",
      " 'secretary' 'section' 'secular' 'seeking' 'segment' 'segments' 'senate'\n",
      " 'sep' 'separate' 'serve' 'set' 'setting' 'sexual' 'shall' 'sheet'\n",
      " 'signatures' 'signed' 'silence' 'sincerely' 'slavery' 'smaller' 'socially'\n",
      " 'sole' 'solely' 'special' 'specific' 'standard' 'standing' 'start'\n",
      " 'startup' 'state' 'statements' 'states' 'statewide' 'std' 'stds' 'store'\n",
      " 'street' 'student' 'students' 'subdivision' 'submit' 'submitted'\n",
      " 'succeeding' 'summary' 'support' 'supreme' 'syllabus' 'syphilis' 'tax'\n",
      " 'teach' 'teachings' 'term' 'terms' 'tests' 'textbook' 'textbooks' 'thank'\n",
      " 'things' 'threats' 'time' 'title' 'tivo' 'today' 'train' 'transparent'\n",
      " 'treasurer' 'trial' 'trustees' 'tsunami' 'tt' 'tuition' 'turn' 'type' 'uc'\n",
      " 'uco' 'ucoca' 'undersigned' 'understand' 'unique' 'united' 'university'\n",
      " 'use' 'used' 'usurp' 'usurped' 'vacant' 'variable' 'vary' 'venue'\n",
      " 'version' 'vi' 'viewable' 'violates' 'volitional' 'voters' 'wanting'\n",
      " 'ward' 'warning' 'way' 'whereon' 'workers' 'www' 'year' 'years']\n"
     ]
    }
   ],
   "source": [
    "# print(filenames)\n",
    "dtm = vectorizer.fit_transform(filenames).toarray()\n",
    "# print(dtm)\n",
    "vocab = np.array(vectorizer.get_feature_names())\n",
    "# print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4961\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='filename',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "[[ 1  0  0 ...,  0  0  0]\n",
      " [ 1  1  0 ...,  0  0  0]\n",
      " [ 0 25 13 ...,  2  1  1]\n",
      " ..., \n",
      " [ 0  1  0 ...,  0  0  0]\n",
      " [ 0  1  0 ...,  0  0  0]\n",
      " [ 0  1  0 ...,  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))\n",
    "print(vectorizer)\n",
    "print(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 4961)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_topics = 7\n",
    "num_top_words = 20\n",
    "clf = decomposition.NMF(n_components=num_topics, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doctopic = clf.fit_transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['section', 'shall', 'person', 'vehicle', 'department', '17', 'code', '10', 'pursuant', 'subdivision', 'program', 'violation', 'date', 'fee', '21', 'page', '05', '09940', 'rn', 'court'], ['uco', 'shall', 'student', 'california', 'president', 'state', 'course', 'university', 'means', 'online', 'division', 'students', 'cost', 'tuition', 'credit', 'courses', 'ii', 'uc', 'regents', 'public'], ['credit', 'tax', 'section', 'shall', 'act', 'california', 'renters', 'year', 'homeowners', 'provisions', 'homeowner', 'housing', 'increase', 'state', '2018', 'home', 'board', 'renter', 'taxable', 'howard'], ['government', 'california', 'section', 'shall', 'parents', 'creator', 'moral', 'schools', 'rights', 'court', 'act', 'initiative', 'constitution', 'state', 'attorney', 'general', 'parental', 'inviolable', 'children', 'child'], ['measure', 'voters', 'initiative', 'california', 'section', 'state', 'voter', 'proposed', 'tax', 'raised', 'letter', 'ca', 'summary', 'coordinator', 'article', 'request', 'approved', 'office', 'constitution', 'title'], ['section', 'california', 'measure', 'taxes', 'vehicle', 'tax', 'proposed', 'initiative', '442', 'hiltachk', 'car', 'gasoline', 'submitted', '916', '2017', 'sacramento', 'constitution', 'voter', 'increases', 'mall'], ['voters', 'local', 'revenue', 'protection', '0034', 'approve', 'diverted', 'fund', 'bond', '11', 'act', 'pursuant', '21', '2018', 'purpose', 'provides', 'intended', 'of2018', 'funds', 'original']]\n"
     ]
    }
   ],
   "source": [
    "topic_words = []\n",
    "for topic in clf.components_:\n",
    "    word_idx = np.argsort(topic)[::-1][0:num_top_words]\n",
    "    topic_words.append([vocab[i] for i in word_idx])\n",
    "\n",
    "print(topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doctopic = doctopic / np.sum(doctopic, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "novel_names = [] \n",
    "\n",
    "for fn in filenames:\n",
    "    basename = os.path.basename(fn)\n",
    "    name, ext = os.path.splitext(basename)\n",
    "    name = name.rstrip('0123456789')\n",
    "    novel_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['txt']\n",
      "[[  0.00000000e+00   9.99999997e-01   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   3.30456218e-09   0.00000000e+00]\n",
      " [  0.00000000e+00   1.22687099e-08   6.80505101e-08   9.99999920e-01\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  9.99999996e-01   6.10846046e-10   3.15314345e-09   0.00000000e+00\n",
      "    0.00000000e+00   5.23325513e-10   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   9.99999947e-01   0.00000000e+00\n",
      "    0.00000000e+00   5.29456708e-08   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.54371491e-02   9.84562851e-01   0.00000000e+00]\n",
      " [  0.00000000e+00   3.97366137e-05   2.59530246e-04   0.00000000e+00\n",
      "    7.86081847e-01   0.00000000e+00   2.13618886e-01]\n",
      " [  2.63109653e-04   0.00000000e+00   0.00000000e+00   4.66322622e-04\n",
      "    7.83100843e-01   1.46941893e-04   2.16022783e-01]]\n",
      "txt: 1 5 6\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-5d3cf556cc87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtop_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoctopic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtop_topics_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnovels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_topics_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "novel_names = np.asarray(novel_names)\n",
    "doctopic_orig = doctopic.copy()\n",
    "num_groups = len(set(novel_names))\n",
    "# print(num_groups)\n",
    "# print(doctopic.copy)\n",
    "doctopic_grouped = np.zeros((num_groups, num_topics))\n",
    "\n",
    "# print(doctopic_grouped)\n",
    "\n",
    "# for i, name in enumerate(sorted(set(novel_names))):\n",
    "#     doctopic_grouped[i, :] = np.mean(doctopic[novel_names == name, :], axis=0)\n",
    "\n",
    "#     doctopic = doctopic_grouped\n",
    "\n",
    "novels = sorted(set(novel_names))\n",
    "print(novels)\n",
    "print(doctopic)\n",
    "for i in range(len(doctopic)):\n",
    "    top_topics = np.argsort(doctopic[i,:])[::-1][0:3]\n",
    "    top_topics_str = ' '.join(str(t) for t in top_topics)\n",
    "    print(\"{}: {}\".format(novels[i], top_topics_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: section shall person vehicle department 17 code 10 pursuant subdivision program violation date fee 21\n",
      "Topic 1: uco shall student california president state course university means online division students cost tuition credit\n",
      "Topic 2: credit tax section shall act california renters year homeowners provisions homeowner housing increase state 2018\n",
      "Topic 3: government california section shall parents creator moral schools rights court act initiative constitution state attorney\n",
      "Topic 4: measure voters initiative california section state voter proposed tax raised letter ca summary coordinator article\n",
      "Topic 5: section california measure taxes vehicle tax proposed initiative 442 hiltachk car gasoline submitted 916 2017\n",
      "Topic 6: voters local revenue protection 0034 approve diverted fund bond 11 act pursuant 21 2018 purpose\n"
     ]
    }
   ],
   "source": [
    "for t in range(len(topic_words)):\n",
    "    print(\"Topic {}: {}\".format(t, ' '.join(topic_words[t][:15])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
